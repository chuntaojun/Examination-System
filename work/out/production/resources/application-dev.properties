# SpringBoot kafka 生产者配置
spring.kafka.bootstrap-servers=192.168.31.217:9092
spring.kafka.producer.acks=all
spring.kafka.producer.retries=0
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.compression-type=gzip
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

spring.kafka.consumer.group-id=1

# 数据库
mysql.url=120.24.90.180:3306/dubbo_cloud_quartz
spring.datasource.jdbc-url=jdbc:mysql://${mysql.url}?useUnicode=true&characterEncoding=utf-8&useSSL=false&allowMultiQueries=true
spring.datasource.username=root
spring.datasource.password=1203
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.hikari.auto-commit=true
spring.datasource.hikari.maximumPoolSize=10
spring.datasource.hikari.validation-timeout=1000
spring.datasource.hikari.connection-timeout=1000
spring.datasource.hikari.max-lifetime=30000
spring.datasource.initialization-mode=always
spring.datasource.schema=classpath:schema/quartz_mysql.sql

# SpringBoot Quartz 任务框架
spring.quartz.jdbc.initialize-schema=embedded
spring.quartz.job-store-type=jdbc

# Dubbo 设置
dubbo.scan.basePackages=com.tensor.org.work.api

# Dubbo Config properties
dubbo.application.id = dubbo-provider-work
dubbo.application.name = dubbo-provider-work

## ProtocolConfig Bean
dubbo.protocol.id = dubbo
dubbo.protocol.name = dubbo
dubbo.protocol.port = 20883

dubbo.provider.url.dao=dubbo://192.168.31.217:20880
dubbo.provider.url.exam=dubbo://192.168.31.217:20881
dubbo.provider.url.user=dubbo://192.168.31.217:20882
dubbo.provider.url.work=dubbo://192.168.31.217:20883

## RegistryConfig Bean
dubbo.registry.id = my-registry
dubbo.registry.address=zookeeper://115.159.3.213:2181

spring.application.name=provider-work

# 自定义配置
# kafka topic定义
kafka.consumer.topic.notice=kafka-topic-notice

